{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8-4.KorNLI(multilingual).ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1jPHd1svzpRjo2rD0wHpQdSeZoKokwRhN","authorship_tag":"ABX9TyO43z3d9+G8uBAnGg2/HjRc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"43f7904aafea4fb4ac6ddf760b4f7d9d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bd738fb2c63b40ec872684af3637f789","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2e95e1e2497a45ec9f58f21f0962e043","IPY_MODEL_86c16646c2a14cd8ba5efd0dee73a599"]}},"bd738fb2c63b40ec872684af3637f789":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e95e1e2497a45ec9f58f21f0962e043":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3002a97b1c0a4dbca6016f5b5aa651f5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b1794dc8f524ee7ba9f623a349cd994"}},"86c16646c2a14cd8ba5efd0dee73a599":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_945f66ae406e4ab9b7ba845a8589ad78","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 6.35kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bfae5bdaeaf54020a2aee19a499feec3"}},"3002a97b1c0a4dbca6016f5b5aa651f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9b1794dc8f524ee7ba9f623a349cd994":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"945f66ae406e4ab9b7ba845a8589ad78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bfae5bdaeaf54020a2aee19a499feec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IywWF9pkaSXe"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMrdCV-pWlyP"},"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from transformers import BertTokenizer, TFBertModel\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"B8YbqSu5MEp3","executionInfo":{"status":"ok","timestamp":1628166365764,"user_tz":-540,"elapsed":1604,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"df01a475-89d1-45f9-a804-0d049eebb01e"},"source":["%cd '/content/drive/MyDrive/Colab Notebooks'\n","df = pd.read_csv('data/multinli.train.koNLI.tsv', delimiter = '\\t', quoting = 3)\n","df = df.dropna()\n","\n","# gold_label을 수치화한다. [contradiction (모순 관계) = 0, entailment (얽힘) = 1, neutral (중립) = 2]\n","df['label'] = LabelEncoder().fit_transform(df['gold_label'])\n","\n","df = df[:10000]   # 시험용으로 조금만 사용\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence1</th>\n","      <th>sentence2</th>\n","      <th>gold_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>개념적으로 크림 스키밍은 제품과 지리라는 두 가지 기본 차원을 가지고 있다.</td>\n","      <td>제품과 지리학은 크림 스키밍을 작동시키는 것이다.</td>\n","      <td>neutral</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>시즌 중에 알고 있는 거 알아? 네 레벨에서 다음 레벨로 잃어버리는 거야 브레이브스...</td>\n","      <td>사람들이 기억하면 다음 수준으로 물건을 잃는다.</td>\n","      <td>entailment</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>우리 번호 중 하나가 당신의 지시를 세밀하게 수행할 것이다.</td>\n","      <td>우리 팀의 일원이 당신의 명령을 엄청나게 정확하게 실행할 것이다.</td>\n","      <td>entailment</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>어떻게 아세요? 이 모든 것이 다시 그들의 정보다.</td>\n","      <td>이 정보는 그들의 것이다.</td>\n","      <td>entailment</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>그래, 만약 네가 테니스화 몇 개를 사러 간다면, 나는 왜 그들이 100달러대에서 ...</td>\n","      <td>테니스화의 가격은 다양하다.</td>\n","      <td>neutral</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           sentence1  ... label\n","0         개념적으로 크림 스키밍은 제품과 지리라는 두 가지 기본 차원을 가지고 있다.  ...     2\n","1  시즌 중에 알고 있는 거 알아? 네 레벨에서 다음 레벨로 잃어버리는 거야 브레이브스...  ...     1\n","2                  우리 번호 중 하나가 당신의 지시를 세밀하게 수행할 것이다.  ...     1\n","3                       어떻게 아세요? 이 모든 것이 다시 그들의 정보다.  ...     1\n","4  그래, 만약 네가 테니스화 몇 개를 사러 간다면, 나는 왜 그들이 100달러대에서 ...  ...     2\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"q8j6-MD-QYfx"},"source":["df['label'] = LabelEncoder().fit_transform(df['gold_label'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r2ZDd3uSafOZ","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["43f7904aafea4fb4ac6ddf760b4f7d9d","bd738fb2c63b40ec872684af3637f789","2e95e1e2497a45ec9f58f21f0962e043","86c16646c2a14cd8ba5efd0dee73a599","3002a97b1c0a4dbca6016f5b5aa651f5","9b1794dc8f524ee7ba9f623a349cd994","945f66ae406e4ab9b7ba845a8589ad78","bfae5bdaeaf54020a2aee19a499feec3"]},"executionInfo":{"status":"ok","timestamp":1628165316839,"user_tz":-540,"elapsed":4587,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"588c9ec3-1c43-4d49-e5ef-ca56ced1a2aa"},"source":["tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt', do_lower_case=False)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43f7904aafea4fb4ac6ddf760b4f7d9d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"afJGpNxIaaAa"},"source":["# Bert Tokenizer\n","# 참조: https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus\n","def bert_tokenizer_v2(sent1, sent2):\n","    \n","    encoded_dict = tokenizer.encode_plus(\n","        text = sent1,\n","        text_pair = sent2,\n","        add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n","        max_length = MAX_LEN,           # Pad & truncate all sentences.\n","        pad_to_max_length = True,\n","        return_attention_mask = True    # Construct attn. masks.\n","    )\n","    \n","    input_id = encoded_dict['input_ids']\n","    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n","    token_type_id = encoded_dict['token_type_ids']  # differentiate two sentences\n","    \n","    return input_id, attention_mask, token_type_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sz_EPoQeb31o"},"source":["def build_data(sent1, sent2):\n","    x_ids = []\n","    x_msk = []\n","    x_typ = []\n","\n","    for s1, s2 in tqdm(zip(sent1, sent2)):\n","        input_id, attention_mask, token_type_id = bert_tokenizer_v2(s1, s2)\n","        x_ids.append(input_id)\n","        x_msk.append(attention_mask)\n","        x_typ.append(token_type_id)\n","\n","    x_ids = np.array(x_ids, dtype=int)\n","    x_msk = np.array(x_msk, dtype=int)\n","    x_typ = np.array(x_typ, dtype=int)\n","\n","    return x_ids, x_msk, x_typ"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtbYGc2-b6Mm","executionInfo":{"status":"ok","timestamp":1628166526964,"user_tz":-540,"elapsed":391,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"b82cd2c0-5718-466c-ca41-ea2072f31603"},"source":["sent1 = df['sentence1']\n","sent2 = df['sentence2']\n","y_label = df['label']\n","MAX_LEN = 24 * 2\n","\n","x_train1, x_test1, x_train2, x_test2, y_train, y_test = train_test_split(sent1, sent2, y_label, test_size=0.1, random_state = 0)\n","\n","x_train_ids, x_train_msk, x_train_typ = build_data(x_train1, x_train2)\n","x_test_ids, x_test_msk, x_test_typ = build_data(x_test1, x_test2)\n","\n","y_train = np.array(y_train).reshape(-1, 1)\n","y_test = np.array(y_test).reshape(-1, 1)\n","\n","x_train_ids.shape, y_train.shape, x_test_ids.shape, y_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((9000, 48), (9000, 1), (1000, 48), (1000, 1))"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgodqIQ8SbIK","executionInfo":{"status":"ok","timestamp":1628166625945,"user_tz":-540,"elapsed":284,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"c2c02baf-99a0-45c2-de69-c07023e06976"},"source":["x_train_ids[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   9011,    117,   9711,  10622, 103995,   9246, 119266,\n","        12965,  48549,    102,   9011,    117,   9711,  10622,   9246,\n","       119284,   9460,   9647, 119138,  12965,  48549,    119,    102,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUS3UaDlSylk","executionInfo":{"status":"ok","timestamp":1628166642597,"user_tz":-540,"elapsed":302,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"407ff234-3ddc-41c7-f69f-3738b825f46a"},"source":["x_train_msk[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkxewOiRS2t5","executionInfo":{"status":"ok","timestamp":1628166658489,"user_tz":-540,"elapsed":303,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"73b16b55-498e-4e7d-9f88-f5877da87ba5"},"source":["x_train_typ[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mA9NKNkSTG9z","executionInfo":{"status":"ok","timestamp":1628166738551,"user_tz":-540,"elapsed":1066,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"2e49345a-8202-44e9-e7f6-1d7a20a68f3e"},"source":["word2idx = tokenizer.vocab\n","idx2word = {v:k for k, v in word2idx.items()}\n","print([idx2word[x] for x in x_train_ids[1]])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['[CLS]', '네', ',', '집', '##을', '완전히', '마', '##쳤', '##어', '##요', '[SEP]', '네', ',', '집', '##을', '마', '##칠', '수', '있', '##었', '##어', '##요', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlK8P_lBeZie","executionInfo":{"status":"ok","timestamp":1628166781243,"user_tz":-540,"elapsed":18041,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"8a994e21-158a-4337-c92a-041849fc974f"},"source":["bert_model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt')\n","bert_model.summary() # bert_model을 확인한다. trainable params = 177,854,978"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"tf_bert_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  177853440 \n","=================================================================\n","Total params: 177,853,440\n","Trainable params: 177,853,440\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HM8cYpMzj-WO","executionInfo":{"status":"ok","timestamp":1628166787800,"user_tz":-540,"elapsed":357,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"0f2018ad-b2e5-4aa9-a241-d74f29904350"},"source":["# TFBertMainLayer는 fine-tuning을 하지 않는다. (시간이 오래 걸림)\n","bert_model.trainable = False\n","bert_model.summary() # bert_model을 다시 확인한다. trainable params = 0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"tf_bert_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  177853440 \n","=================================================================\n","Total params: 177,853,440\n","Trainable params: 0\n","Non-trainable params: 177,853,440\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsTdMX79jR1B","executionInfo":{"status":"ok","timestamp":1628166913132,"user_tz":-540,"elapsed":36695,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"c3c84d1a-cd1a-42f5-b7bf-4dc3c086a805"},"source":["# BERT 입력\n","# ---------\n","x_input_ids = Input(batch_shape = (None, MAX_LEN), dtype = tf.int32)\n","x_input_msk = Input(batch_shape = (None, MAX_LEN), dtype = tf.int32)\n","x_input_typ = Input(batch_shape = (None, MAX_LEN), dtype = tf.int32)\n","\n","# BERT 출력\n","# ---------\n","output_bert = bert_model([x_input_ids, x_input_msk, x_input_typ])[1]\n","\n","# Downstream task : 자언어 추론 (NLI)\n","# ----------------------------------\n","y_output = Dense(3, activation = 'softmax')(output_bert)\n","model = Model([x_input_ids, x_input_msk, x_input_typ], y_output)\n","model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam(learning_rate = 0.001))\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5aef574d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5aef574d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f5b0a727170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f5b0a727170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 48)]         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 48)]         0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 48)]         0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     TFBaseModelOutputWit 177853440   input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 3)            2307        tf_bert_model[0][1]              \n","==================================================================================================\n","Total params: 177,855,747\n","Trainable params: 2,307\n","Non-trainable params: 177,853,440\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JD7lLwRLmLZ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628166997259,"user_tz":-540,"elapsed":51584,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"05a7ebcc-c64c-4d94-987e-8dd76eabf153"},"source":["x_train = [x_train_ids, x_train_msk, x_train_typ]\n","x_test = [x_test_ids, x_test_msk, x_test_typ]\n","hist = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=1, batch_size=1024)\n","\n","# Epoch 1/3\n","# 157/157 [==============================] - ETA: 0s - loss: 0.6245WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","# WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","# 157/157 [==============================] - 936s 6s/step - loss: 0.6245 - val_loss: 0.6070\n","# Epoch 2/3\n","# 157/157 [==============================] - 926s 6s/step - loss: 0.6184 - val_loss: 0.6023\n","# Epoch 3/3\n","# 157/157 [==============================] - 903s 6s/step - loss: 0.6134 - val_loss: 0.5973\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","9/9 [==============================] - ETA: 0s - loss: 1.1073WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","9/9 [==============================] - 42s 4s/step - loss: 1.1073 - val_loss: 1.0937\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KASsXJZcxdIT"},"source":["# Loss history를 그린다\n","plt.plot(hist.history['loss'], label='Train loss')\n","plt.plot(hist.history['val_loss'], label = 'Test loss')\n","plt.legend()\n","plt.title(\"Loss history\")\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"loss\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XntTvnBBoER8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628167036077,"user_tz":-540,"elapsed":5997,"user":{"displayName":"조성현","photoUrl":"","userId":"00956016439237072792"}},"outputId":"684cf73b-6850-40b7-8e3d-03a740d25723"},"source":["# 시험 데이터로 학습 성능을 평가한다\n","pred = model.predict(x_test)\n","y_pred = np.argmax(pred, axis=1).reshape(-1, 1)\n","accuracy = (y_pred == y_test).mean()\n","print(\"\\nAccuracy = %.2f %s\" % (accuracy * 100, '%'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","\n","Accuracy = 33.60 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IDNrnshhtxmL"},"source":[""],"execution_count":null,"outputs":[]}]}